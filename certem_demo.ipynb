{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import graphviz\n",
    "import seaborn as sns\n",
    "from certa.utils import merge_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.rendered_html th {max-width: 150px;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wide window setting\n",
    "from IPython.display import HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "HTML(\"<style>.rendered_html th {max-width: 150px;}</style>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom plot for saliencies\n",
    "def custom_plot(df, name):\n",
    "    f1 = plt.figure()\n",
    "    ax1 = f1.add_subplot(111)\n",
    "    df.plot(kind = 'bar',ax=ax1)\n",
    "    img_path = 'data_new/img/'+name+'.png'\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()\n",
    "    return  [f1, img_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597f0d7373414eb7b7cbcc7cd0776d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Text(value='', description='P0'), Text(value='', description='P1'), Text(value='', description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab_contents = ['P0', 'P1', 'P2', 'P3', 'P4']\n",
    "children = [widgets.Text(description=name) for name in tab_contents]\n",
    "tab = widgets.Tab()\n",
    "tab.children = children\n",
    "for i in range(len(children)):\n",
    "    tab.set_title(i, str(i))\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "datasets = [name for name in os.listdir(\"data\")]\n",
    "datasets.remove('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "datadirs = dict()\n",
    "datadirs['AB'] = '/home/tteofili/dev/cheapER/datasets/abt_buy'\n",
    "datadirs['BA'] = '/home/tteofili/dev/cheapER/datasets/beers'\n",
    "datadirs['IA'] = '/home/tteofili/dev/cheapER/datasets/itunes_amazon'\n",
    "train_dfs = dict()\n",
    "\n",
    "for dataset in datasets:\n",
    "    datadir = datadirs[dataset]\n",
    "    lsource = pd.read_csv(datadir + '/tableA.csv')\n",
    "    rsource = pd.read_csv(datadir + '/tableB.csv')\n",
    "    gt = pd.read_csv(datadir + '/train.csv')\n",
    "    train_df = merge_sources(gt, 'ltable_', 'rtable_', lsource, rsource, ['label'], ['id'])\n",
    "    train_dfs[dataset] = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data selection widgets\n",
    "datasets_dropdown = widgets.Dropdown(\n",
    "    options=datasets,\n",
    "    value=datasets[0],\n",
    "    description='Dataset',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "gt_filter = widgets.RadioButtons(\n",
    "    options=['Any', 'NO-MATCH', 'MATCH'],\n",
    "    description='Label',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "pred_filter = widgets.RadioButtons(\n",
    "    options=['Any', 'NO-MATCH', 'MATCH'],\n",
    "    description='Prediction',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "sys_label = widgets.Label(\n",
    "    value='ER Systems'\n",
    ")\n",
    "de_cb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='DeepER',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    ")\n",
    "dm_cb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='DeepMatcher',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    ")\n",
    "dt_cb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Ditto',\n",
    "    disabled=False,\n",
    "    indent=False,\n",
    ")\n",
    "\n",
    "box_layout = widgets.Layout(display='flex',\n",
    "                flex_flow='column',\n",
    "                align_items='center')\n",
    "cf_name_dict = {'shapc' : 'SHAP-C', 'limec': 'LIME-C', 'certa': 'CERTA', 'dice_random' : 'DiCE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color maps\n",
    "cb = sns.light_palette(\"blue\", as_cmap=True)\n",
    "cr = sns.light_palette(\"red\", as_cmap=True)\n",
    "cg = sns.light_palette(\"green\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_prediction(x, columns=['DeepER', 'DeepMatcher', 'Ditto', 'prediction', 'label', 'match_score']):\n",
    "    rh = f\"background-color:red\" \n",
    "    gh = f\"background-color:green\" \n",
    "    df1 = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    for column in columns:\n",
    "        if column in x.columns:\n",
    "            ig = x[column] > 0.5\n",
    "            ir = x[column] < 0.5\n",
    "            df1.loc[ir, column] = rh\n",
    "            df1.loc[ig, column] = gh\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(dataset, deeper, dm, ditto, pred_filter, gt_filter):\n",
    "    out2.clear_output()\n",
    "    samples = pd.read_csv('data_new/'+dataset+'/samples.csv').drop(['ltable_id', 'rtable_id'], axis=1)\n",
    "    if not deeper:\n",
    "        samples = samples.drop(['DeepER'], axis=1)\n",
    "    if not dm:\n",
    "        samples = samples.drop(['DeepMatcher'], axis=1)\n",
    "    if not ditto:\n",
    "        samples = samples.drop(['Ditto'], axis=1)\n",
    "    if gt_filter == 'NO-MATCH':\n",
    "        samples = samples[samples['label']==0]\n",
    "    if gt_filter == 'MATCH':\n",
    "        samples = samples[samples['label']==1]\n",
    "    if pred_filter == 'NO-MATCH':\n",
    "        samples = samples[samples['DeepER']<0.5]\n",
    "    if pred_filter == 'MATCH':\n",
    "        samples = samples[('DeepER' in samples.columns and samples['DeepER']>0.5) | ('DeepMatcher' in samples.columns and samples['DeepMatcher']>0.5) | ('Ditto' in samples.columns and samples['Ditto']>0.5)]\n",
    "    samples = samples.loc[:, ~samples.columns.str.contains('^Unnamed')]\n",
    "    explain_buttons = []\n",
    "    for idx in samples.index:\n",
    "        explain_button = widgets.Button(description=\"Explain Item \"+str(idx))\n",
    "        def on_explain_clicked(b):\n",
    "            out2.clear_output()\n",
    "            saliencies = dict()\n",
    "            cfs = dict()\n",
    "            item_idx = int(b.description[-1])\n",
    "            if deeper:\n",
    "                saliency = pd.read_csv('data_new/'+dataset+'/DeepER/certa.csv')['explanation'].iloc[item_idx]\n",
    "                first_cf = pd.read_csv('data_new/'+dataset+'/DeepER/'+str(item_idx)+'/certa.csv').iloc[0]\n",
    "                saliencies['DeepER'] = saliency\n",
    "                cfs['DeepER'] = first_cf.copy()\n",
    "            if dm:\n",
    "                saliency = pd.read_csv('data_new/'+dataset+'/DeepMatcher/certa.csv')['explanation'].iloc[item_idx]\n",
    "                first_cf = pd.read_csv('data_new/'+dataset+'/DeepMatcher/'+str(item_idx)+'/certa.csv').iloc[0]\n",
    "                saliencies['DeepMatcher'] = saliency\n",
    "                cfs['DeepMatcher'] = first_cf.copy()\n",
    "            if ditto:\n",
    "                saliency = pd.read_csv('data_new/'+dataset+'/Ditto/certa.csv')['explanation'].iloc[item_idx]\n",
    "                first_cf = pd.read_csv('data_new/'+dataset+'/Ditto/'+str(item_idx)+'/certa.csv').iloc[0]\n",
    "                saliencies['Ditto'] = saliency\n",
    "                cfs['Ditto'] = first_cf.copy()\n",
    "            saliencies_box = []\n",
    "            saliency_dfs = []\n",
    "            for k in saliencies.keys():\n",
    "                saliency_df = pd.DataFrame(eval(saliencies[k]),index=[0])\n",
    "                cnv, path = custom_plot(saliency_df, dataset+'_'+k+'_'+str(item_idx))\n",
    "                img = widgets.Image(value=open(path, 'rb').read(), format='png')\n",
    "\n",
    "                saliency_df['model'] = k\n",
    "                saliency_dfs.append(saliency_df)\n",
    "                \n",
    "                inspect_button = widgets.Button(description='Inspect '+k)\n",
    "                def inspect_button_click(ib):\n",
    "                    selected_model = ib.description[8:]\n",
    "                    single_pred = samples.iloc[item_idx]\n",
    "                    for sm in ['DeepER', 'DeepMatcher', 'Ditto']:\n",
    "                        if sm != selected_model:\n",
    "                            single_pred = single_pred.drop(sm)\n",
    "                    expl_data_df = pd.read_csv('data_new/'+dataset+'/'+selected_model+'/certa.csv')\n",
    "                    pnn_df = pd.DataFrame(eval(expl_data_df['explanation'].iloc[item_idx]), index=[0])\n",
    "                    \n",
    "                    pss_dict = eval(expl_data_df['summary'].iloc[item_idx])\n",
    "                    pss_dfs = dict()\n",
    "                    for k, v in pss_dict.items():\n",
    "                        attrs = k.split('/')\n",
    "                        no_attrs = len(attrs)\n",
    "                        if not no_attrs in pss_dfs:\n",
    "                            pss_dfs[no_attrs] = {' '.join(attrs): v}\n",
    "                        else:\n",
    "                            cd = pss_dfs[no_attrs]\n",
    "                            cd.update({' '.join(attrs): v})\n",
    "                            pss_dfs[no_attrs] = cd\n",
    "                    pss_outs = []\n",
    "                    for k, v in pss_dfs.items():\n",
    "                        pssk_out = widgets.Output()\n",
    "                        with pssk_out:\n",
    "                            display(pd.DataFrame(v, index=[0]).style.background_gradient(cmap=cg, axis=1, low=0.1, high=0.6))\n",
    "                        pss_outs.append(pssk_out)\n",
    "                    pred_out = widgets.Output()\n",
    "                    with pred_out:\n",
    "                        display(pd.DataFrame(single_pred).T.style.apply(highlight_prediction, axis=None))\n",
    "                    out_pnn = widgets.Output()\n",
    "                    with out_pnn:\n",
    "                        display(pnn_df.style.background_gradient(cmap=cr, axis=1, low=0.1, high=0.6))\n",
    "                    \n",
    "                    item_data_path = 'data_new/'+dataset+'/'+selected_model+'/'+str(item_idx)+'/'\n",
    "                    tr_files = [f for f in Path(item_data_path).iterdir() if f.match(\"triangle_*.csv\")]\n",
    "                    tr_dfs = []\n",
    "                    for tr_file in tr_files:\n",
    "                        tr_dfs.append(pd.read_csv(tr_file).drop(['Unnamed: 0'], axis=1))\n",
    "                    lt_files = [f for f in Path(item_data_path).iterdir() if f.match(\"lattice_*.dot\")]\n",
    "                    tr_slider = widgets.IntSlider(value=0, min=0, max=len(tr_files)-1, step=1, description='Triangle:', disabled=False, continuous_update=False, orientation='horizontal',\n",
    "                            readout=True, readout_format='d')\n",
    "                    def tr_slide(slide):\n",
    "                        out_df = widgets.Output()\n",
    "                        with out_df:\n",
    "                            display(tr_dfs[slide].style.apply(highlight_prediction, axis=None))\n",
    "                        display(widgets.VBox([widgets.Image(value=graphviz.Source.from_file(lt_files[slide]).pipe(format='png'),format='png'), out_df], layout=box_layout))\n",
    "                    tr_out = widgets.interactive_output(tr_slide, {'slide': tr_slider})\n",
    "                    \n",
    "                    with out2:\n",
    "                        display(widgets.VBox([widgets.Label(selected_model+' Prediction'), pred_out, \n",
    "                                          widgets.Label('Probability of Necessity'),\n",
    "                                          out_pnn,\n",
    "                                          widgets.Label('Probability of Sufficiency'),\n",
    "                                          widgets.VBox(pss_outs, layout=box_layout),\n",
    "                                          widgets.HBox([tr_slider]), tr_out], layout=box_layout))\n",
    "                inspect_button.on_click(inspect_button_click)   \n",
    "                \n",
    "                debug_button = widgets.Button(description=\"Debug \"+k)\n",
    "                def on_debug_clicked(b):\n",
    "                    #out2.clear_output()\n",
    "                    selected_model = b.description[6:]\n",
    "                    \n",
    "                    single_pred = samples.loc[item_idx]\n",
    "                    for sm in ['DeepER', 'DeepMatcher', 'Ditto']:\n",
    "                        if sm != selected_model:\n",
    "                            single_pred = single_pred.drop(sm)\n",
    "                    pred_out = widgets.Output()\n",
    "                    with pred_out:\n",
    "                        display(pd.DataFrame(single_pred).T.style.apply(highlight_prediction, axis=None))\n",
    "                    \n",
    "                    expl_data_df = pd.read_csv('data_new/'+dataset+'/'+selected_model+'/certa.csv')\n",
    "\n",
    "                    pnn_df = pd.DataFrame(eval(expl_data_df['explanation'].iloc[item_idx]), index=[0])\n",
    "                    out_pnn = widgets.Output()\n",
    "                    with out_pnn:\n",
    "                        display(pnn_df.style.background_gradient(cmap=cr, axis=1, low=0.1, high=0.6))\n",
    "                    \n",
    "                    pss_dict = eval(expl_data_df['summary'].iloc[item_idx])\n",
    "                    pss_dfs = dict()\n",
    "                    for k, v in pss_dict.items():\n",
    "                        attrs = k.split('/')\n",
    "                        no_attrs = len(attrs)\n",
    "                        if not no_attrs in pss_dfs:\n",
    "                            pss_dfs[no_attrs] = {' '.join(attrs): v}\n",
    "                        else:\n",
    "                            cd = pss_dfs[no_attrs]\n",
    "                            cd.update({' '.join(attrs): v})\n",
    "                            pss_dfs[no_attrs] = cd\n",
    "                    pss_outs = []\n",
    "                    for k, v in pss_dfs.items():\n",
    "                        pssk_out = widgets.Output()\n",
    "                        with pssk_out:\n",
    "                            display(pd.DataFrame(v, index=[0]).style.background_gradient(cmap=cg, axis=1, low=0.1, high=0.6))\n",
    "                        pss_outs.append(pssk_out)\n",
    "                    \n",
    "                    if float(single_pred[selected_model]) > 0.5:\n",
    "                        perturb = 'mask'\n",
    "                    else:\n",
    "                        perturb = 'copy'\n",
    "                    \n",
    "                    saliency_graphs = []\n",
    "                    topk_slider = widgets.IntSlider(value=0, min=0, max=7, step=1, description='Top K:', disabled=False, continuous_update=False, orientation='horizontal',\n",
    "                            readout=True, readout_format='d')\n",
    "                    sgt = 'certa'\n",
    "                    try:\n",
    "                        sg_path = 'data_new/'+dataset+'/'+selected_model+'/'+str(item_idx)+'/sg/'+sgt+'_'+perturb+'.png'\n",
    "                        saliency_graph = widgets.VBox([widgets.Image(value=open(sg_path, 'rb').read(), \n",
    "                                                   format='png', width=400, height=240,), widgets.Label(value=sgt),\n",
    "                                                      widgets.Label('Debug Data'), topk_slider], layout=box_layout)\n",
    "                        saliency_graphs.append(saliency_graph)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    \n",
    "                    def debug_data(top_k):\n",
    "                        saliency = pnn_df.to_dict(orient='list')\n",
    "                        explanation_attributes = sorted(saliency, key=saliency.get, reverse=True)[:top_k]\n",
    "                        train_df = train_dfs[dataset]\n",
    "                        search_rows = dict()\n",
    "                        train_rows = pd.DataFrame()\n",
    "                        for search_column in explanation_attributes:\n",
    "                            search_value = single_pred[search_column]\n",
    "                            search_rows[search_column] = search_value\n",
    "                            res = train_df[train_df[search_column].str.contains(search_value)]\n",
    "                            train_rows = pd.concat([train_rows, res], axis=0).drop_duplicates()\n",
    "                        \n",
    "                        out_result_rows = widgets.Output()\n",
    "                        out_search_rows = widgets.Output()\n",
    "                        if len(search_rows) > 0:\n",
    "                            with out_search_rows:\n",
    "                                display(pd.DataFrame(search_rows, index=[0]))\n",
    "                        if len(train_rows) > 0:\n",
    "                            with out_result_rows:\n",
    "                                display(train_rows.reset_index(drop=True).style.apply(highlight_prediction, axis=None))\n",
    "                        display(widgets.VBox([out_search_rows, out_result_rows]))\n",
    "                    \n",
    "                    data_debug_out = widgets.interactive_output(debug_data, {'top_k': topk_slider})\n",
    "                    \n",
    "                    for sgt in ['mojito','landmark','shap']:\n",
    "                        try:\n",
    "                            sg_path = 'data_new/'+dataset+'/'+selected_model+'/'+str(item_idx)+'/sg/'+sgt+'_'+perturb+'.png'\n",
    "                            saliency_graph = widgets.VBox([widgets.Image(value=open(sg_path, 'rb').read(), \n",
    "                                                       format='png', width=400, height=240,), widgets.Label(value=sgt)], layout=box_layout)\n",
    "                            saliency_graphs.append(saliency_graph)\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    cfm_outs = [] \n",
    "                    cfm_outs.append(widgets.Label('Counterfactual Examples'))\n",
    "                    for cfm in ['certa', 'dice_random', 'shapc', 'limec']:\n",
    "                        try:\n",
    "                            cf_path = 'data_new/'+dataset+'/'+selected_model+'/'+str(item_idx)+'/'+cfm+'.csv'\n",
    "                            cfm_df = pd.read_csv(cf_path)\n",
    "                            for c in ['alteredAttributes', 'droppedValues', 'copiedValues', 'triangle', 'attr_count', 'nomatch_score']:\n",
    "                                if c in cfm_df.columns:\n",
    "                                    cfm_df = cfm_df.drop([c], axis=1)\n",
    "                            for rc in ['match_score', 'label']:\n",
    "                                if rc in cfm_df.columns:\n",
    "                                    cfm_df['prediction'] = cfm_df[rc].copy()\n",
    "                                    cfm_df = cfm_df.drop([rc], axis=1)\n",
    "                            cfm_out = widgets.Output()\n",
    "                            with cfm_out:\n",
    "                                display(cfm_df.loc[:, ~cfm_df.columns.str.contains('^Unnamed')].style.apply(highlight_prediction, axis=None))\n",
    "                            cfm_outs.append(widgets.VBox([widgets.Label(cf_name_dict[cfm]), cfm_out], layout=box_layout))\n",
    "                        except:\n",
    "                            pass\n",
    "                    cf_metrics_label = widgets.Label('Counterfactual Metrics')\n",
    "                    cfm_outs.append(cf_metrics_label)\n",
    "                    \n",
    "                    cf_metrics_out = widgets.Output()\n",
    "                    with cf_metrics_out:\n",
    "                        display(pd.read_csv('data_new/'+dataset+'/'+selected_model+'/cf_metrics.csv'))\n",
    "                    cfm_outs.append(cf_metrics_out)                    \n",
    "                    \n",
    "                    saliency_tab = widgets.VBox([widgets.Label('Saliency Graphs'), widgets.HBox(saliency_graphs), data_debug_out], layout=box_layout)\n",
    "                    cf_tab = widgets.VBox(cfm_outs, layout=box_layout)\n",
    "                    children = [saliency_tab, cf_tab] \n",
    "                    debug_tab = widgets.Tab(children = children)\n",
    "                    debug_tab.set_title(0, 'Saliency')\n",
    "                    debug_tab.set_title(1, 'Counterfactual')\n",
    "                    #debug_tab.children = children\n",
    "                    #debug_tab.titles = ['Saliency', 'Counterfactual']\n",
    "                    \n",
    "                    out2_data = widgets.VBox([widgets.Label(selected_model+' Prediction'), pred_out, \n",
    "                                              widgets.Label('Probability of Necessity'), out_pnn, \n",
    "                                              widgets.Label('Probability of Sufficiency'),\n",
    "                                              widgets.VBox(pss_outs, layout=box_layout),\n",
    "                                              debug_tab], layout=box_layout)\n",
    "                    with out2:\n",
    "                        display(out2_data)\n",
    "                        \n",
    "                debug_button.on_click(on_debug_clicked)\n",
    "                saliencies_box.append(widgets.VBox([img , inspect_button, debug_button], layout=box_layout))\n",
    "            \n",
    "            cfs_df = pd.DataFrame.from_dict(cfs).T.drop(['alteredAttributes', 'attr_count', 'copiedValues', 'droppedValues', 'triangle', 'nomatch_score'], axis=1)\n",
    "            cfs_df['prediction'] = cfs_df['match_score'].copy()\n",
    "            cfs_df = cfs_df.drop(['match_score'], axis=1)\n",
    "            cfs_df = cfs_df.loc[:, ~cfs_df.columns.str.contains('^Unnamed')]\n",
    "            out_cfs = widgets.Output()\n",
    "            out_cfs.append_display_data(cfs_df.style.apply(highlight_prediction, axis=None))\n",
    "            \n",
    "            o_out = widgets.Output()\n",
    "            if len(saliency_dfs) > 0:\n",
    "                saliencies_df = pd.concat(saliency_dfs, axis=0, ignore_index=True)\n",
    "                with o_out:\n",
    "                    display(saliencies_df.style.background_gradient(cmap=cb, axis=1, low=0.1, high=0.6))\n",
    "            out2.clear_output()\n",
    "            out2_data = widgets.VBox([o_out, widgets.HBox(saliencies_box), out_cfs], layout=box_layout)\n",
    "            \n",
    "            with out2:\n",
    "                display(out2_data)\n",
    "        explain_button.on_click(on_explain_clicked)\n",
    "        explain_buttons.append(explain_button)\n",
    "        \n",
    "    explain_buttons_box = widgets.HBox(explain_buttons)\n",
    "    samples_out = widgets.Output()\n",
    "    with samples_out:\n",
    "        display(samples.style.apply(highlight_prediction, axis=None))\n",
    "    display(widgets.HBox([samples_out, widgets.VBox([explain_buttons_box])], layout=box_layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.interactive_output(f, {'dataset': datasets_dropdown, 'deeper': de_cb, 'dm': dm_cb, 'ditto':dt_cb, 'pred_filter': pred_filter, 'gt_filter': gt_filter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_box = widgets.VBox([datasets_dropdown])\n",
    "second_box = widgets.HBox([sys_label, widgets.VBox([de_cb, dm_cb, dt_cb])])\n",
    "third_box = widgets.VBox([gt_filter])\n",
    "fourth_box = widgets.VBox([pred_filter])\n",
    "top1 = widgets.HBox([first_box, second_box, third_box, fourth_box])\n",
    "ui = widgets.VBox([top1, out, out2], layout=box_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b858b3f632e549ddbf57f304e1b57028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Dataset', index=1, options=('AB', 'BA', 'IA…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
